{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.0371, Test Loss: 0.0353, Accuracy: 75.83%\n",
      "Epoch [2/50], Train Loss: 0.0264, Test Loss: 0.0089, Accuracy: 96.67%\n",
      "Epoch [3/50], Train Loss: 0.0215, Test Loss: 0.0593, Accuracy: 67.50%\n",
      "Epoch [4/50], Train Loss: 0.0177, Test Loss: 0.0089, Accuracy: 94.58%\n",
      "Epoch [5/50], Train Loss: 0.0159, Test Loss: 0.0185, Accuracy: 89.17%\n",
      "Epoch [6/50], Train Loss: 0.0096, Test Loss: 0.0024, Accuracy: 98.75%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set dataset paths\n",
    "train_dir = r\"E:\\Thesis-8th sem\\Dataset\\archive\\breast-cancer-dataset\\Train\"\n",
    "test_dir = r\"E:\\Thesis-8th sem\\Dataset\\archive\\breast-cancer-dataset\\Test\"\n",
    "\n",
    "# Data transformations with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), shear=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.GaussianBlur(3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Custom Dataset class\n",
    "class BreastCancerDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.image_paths, self.labels = self.load_images()\n",
    "\n",
    "    def load_images(self):\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "        for label_folder in os.listdir(self.directory):\n",
    "            label_path = os.path.join(self.directory, label_folder)\n",
    "            if os.path.isdir(label_path):\n",
    "                label = 0 if 'benign' in label_folder.lower() else 1\n",
    "                for file in os.listdir(label_path):\n",
    "                    if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        image_paths.append(os.path.join(label_path, file))\n",
    "                        labels.append(label)\n",
    "        return image_paths, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = BreastCancerDataset(train_dir, transform=transform)\n",
    "test_dataset = BreastCancerDataset(test_dir, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Define Hybrid CNN + ViT Model\n",
    "class CNN_ViT_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ViT_Model, self).__init__()\n",
    "        \n",
    "        # CNN (ResNet-18) as Feature Extractor\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn.fc = nn.Identity()  # Remove final classification layer\n",
    "        self.cnn_out_features = 512  # ResNet-18 outputs 512 features\n",
    "\n",
    "        # ViT (Vision Transformer) for Global Context Learning\n",
    "        self.vit = models.vit_b_16(pretrained=True)\n",
    "        self.vit.heads.head = nn.Identity()  # Remove ViT classification head\n",
    "        self.vit_out_features = 768  # ViT outputs 768 features\n",
    "\n",
    "        # Fusion Layer + Final Classifier\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.cnn_out_features + self.vit_out_features, 512),  # Corrected input size\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 2)  # Binary classification (Benign/Malignant)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x)  # Extract local features using CNN (ResNet-18) -> (Batch, 512)\n",
    "        vit_features = self.vit(x)  # Extract global features using ViT (ViT-B/16) -> (Batch, 768)\n",
    "        combined = torch.cat((cnn_features, vit_features), dim=1)  # Concatenate features -> (Batch, 1280)\n",
    "        return self.fc(combined)\n",
    "\n",
    "# Initialize model\n",
    "model = CNN_ViT_Model()\n",
    "\n",
    "# Custom Focal Loss (Handles Class Imbalance Better)\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = nn.functional.cross_entropy(logits, targets, reduction='none')\n",
    "        p_t = torch.exp(-ce_loss)\n",
    "        loss = self.alpha * (1 - p_t) ** self.gamma * ce_loss\n",
    "        return loss.mean()\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "# Optimizer: AdamW (Better Generalization)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training with Early Stopping (Patience = 5)\n",
    "num_epochs = 50\n",
    "best_loss = float(\"inf\")\n",
    "patience = 5\n",
    "counter = 0\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Evaluate test loss\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    # Early stopping condition\n",
    "    if avg_test_loss < best_loss:\n",
    "        best_loss = avg_test_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_hybrid_model.pth\")  # Save the best model\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "# Load the best model and evaluate\n",
    "model.load_state_dict(torch.load(\"best_hybrid_model.pth\"))\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "final_accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "print(f'Final Test Accuracy: {final_accuracy:.2f}%')\n",
    "\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Testing Loss\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
